{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import numpy.random as rand\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model net\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(None, 300, 300)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#model = keras.Sequential([\n",
    "#    keras.layers.Flatten(input_shape=(None, 300, 300)),\n",
    "#    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#    keras.layers.Dense(4, activation=tf.nn.softmax)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "url_train = r'Data/Train' + '/*'\n",
    "url_val = r'Data/val' + '/*'\n",
    "url_test = r'Data/test' + '/*'\n",
    "img_size_h = 300\n",
    "img_size_w = 300\n",
    "\n",
    "img_list_train = []\n",
    "lable_list_train = []\n",
    "\n",
    "img_list_val = []\n",
    "lable_list_val = []\n",
    "\n",
    "img_list_test = []\n",
    "lable_list_test = []\n",
    "\n",
    "cooked_img_list_train = []\n",
    "cooked_lable_list_train = []\n",
    "\n",
    "cooked_img_list_val = []\n",
    "cooked_lable_list_val = []\n",
    "\n",
    "cooked_img_list_test = []\n",
    "cooked_lable_list_test = []\n",
    "\n",
    "\n",
    "#load uncooked train data\n",
    "class_img = len(glob.glob(url_train))\n",
    "name_url_class = glob.glob(url_train)\n",
    "\n",
    "for i in range(class_img):\n",
    "    all_url_img = glob.glob(name_url_class[i] + '/*')\n",
    "    for y in all_url_img:\n",
    "        img = cv.imread(y)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img = cv.resize(img, (img_size_w, img_size_h))\n",
    "        img_list_train.append(img)\n",
    "        lable_list_train.append(i)\n",
    "\n",
    "#load uncooked val data\n",
    "class_img = len(glob.glob(url_val))\n",
    "name_url_class = glob.glob(url_val)\n",
    "\n",
    "for i in range(class_img):\n",
    "    all_url_img = glob.glob(name_url_class[i] + '/*')\n",
    "    for y in all_url_img:\n",
    "        img = cv.imread(y)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img = cv.resize(img, (img_size_w, img_size_h))\n",
    "        img_list_val.append(img)\n",
    "        lable_list_val.append(i)\n",
    "\n",
    "#load uncooked test data\n",
    "class_img = len(glob.glob(url_test))\n",
    "name_url_class = glob.glob(url_test)\n",
    "\n",
    "for i in range(class_img):\n",
    "    all_url_img = glob.glob(name_url_class[i] + '\\*')\n",
    "    for y in all_url_img:\n",
    "        img = cv.imread(y)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img = cv.resize(img, (img_size_w, img_size_h))\n",
    "        img_list_test.append(img)\n",
    "        lable_list_test.append(i)\n",
    "\n",
    "#create lists cooked data\n",
    "for i in np.random.randint(0, len(img_list_train), len(img_list_train)):\n",
    "    cooked_img_list_train.append(img_list_train[i])\n",
    "    cooked_lable_list_train.append(lable_list_train[i])\n",
    "\n",
    "for i in np.random.randint(0, len(img_list_val), len(img_list_val)):\n",
    "    cooked_img_list_val.append(img_list_val[i])\n",
    "    cooked_lable_list_val.append(lable_list_val[i])\n",
    "\n",
    "for i in np.random.randint(0, len(img_list_test), len(img_list_test)):\n",
    "    cooked_img_list_test.append(img_list_test[i])\n",
    "    cooked_lable_list_test.append(lable_list_test[i])\n",
    "\n",
    "cooked_img_list_train = np.array(cooked_img_list_train ,dtype='float32')\n",
    "cooked_img_list_val = np.array(cooked_img_list_val ,dtype='float32')\n",
    "cooked_img_list_test = np.array(cooked_img_list_test ,dtype='float32')\n",
    "   \n",
    "cooked_img_list_train = cooked_img_list_train / 255\n",
    "cooked_img_list_val = cooked_img_list_val / 255\n",
    "cooked_img_list_test = cooked_img_list_test / 255\n",
    "\n",
    "cooked_img_list_train =  np.expand_dims(cooked_img_list_train, axis=0)\n",
    "cooked_img_list_val =  np.expand_dims(cooked_img_list_val, axis=0)\n",
    "cooked_img_list_test =  np.expand_dims(cooked_img_list_test, axis=0)\n",
    "\n",
    "cooked_lable_list_train = np.array(cooked_lable_list_train ,dtype='uint8')\n",
    "cooked_lable_list_val = np.array(cooked_lable_list_val ,dtype='uint8')\n",
    "cooked_lable_list_test = np.array(cooked_lable_list_test ,dtype='uint8')\n",
    "\n",
    "#cooked_lable_list_train =  np.expand_dims(cooked_lable_list_train, axis=0)\n",
    "#cooked_lable_list_val =  np.expand_dims(cooked_lable_list_val, axis=0)\n",
    "#cooked_lable_list_test =  np.expand_dims(cooked_lable_list_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 701, 300, 300)\n",
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[0.827451   0.8156863  0.8392157  ... 0.8784314  0.8862745\n",
      "    0.89411765]\n",
      "   [0.8352941  0.8235294  0.8117647  ... 0.84313726 0.8745098\n",
      "    0.8901961 ]\n",
      "   [0.83137256 0.83137256 0.83137256 ... 0.83137256 0.8352941\n",
      "    0.85490197]\n",
      "   ...\n",
      "   [0.827451   0.8352941  0.84313726 ... 0.11764706 0.1254902\n",
      "    0.05882353]\n",
      "   [0.81960785 0.827451   0.8392157  ... 0.10588235 0.15294118\n",
      "    0.12941177]\n",
      "   [0.827451   0.8117647  0.8235294  ... 0.14117648 0.14117648\n",
      "    0.10196079]]\n",
      "\n",
      "  [[0.9764706  0.98039216 0.96862745 ... 0.59607846 0.6\n",
      "    0.60784316]\n",
      "   [0.99215686 0.9882353  0.9764706  ... 0.5921569  0.5921569\n",
      "    0.6       ]\n",
      "   [0.99607843 0.99215686 0.98039216 ... 0.5921569  0.5882353\n",
      "    0.5921569 ]\n",
      "   ...\n",
      "   [0.38039216 0.37254903 0.3764706  ... 0.5686275  0.5647059\n",
      "    0.5568628 ]\n",
      "   [0.3764706  0.37254903 0.3764706  ... 0.5529412  0.54901963\n",
      "    0.54509807]\n",
      "   [0.38431373 0.3764706  0.36862746 ... 0.56078434 0.56078434\n",
      "    0.5529412 ]]\n",
      "\n",
      "  [[0.6784314  0.6627451  0.6784314  ... 0.58431375 0.5921569\n",
      "    0.60784316]\n",
      "   [0.7019608  0.68235296 0.67058825 ... 0.57254905 0.5647059\n",
      "    0.58431375]\n",
      "   [0.70980394 0.6901961  0.69803923 ... 0.5647059  0.56078434\n",
      "    0.56078434]\n",
      "   ...\n",
      "   [0.5019608  0.63529414 0.61960787 ... 0.23529412 0.2\n",
      "    0.21960784]\n",
      "   [0.6117647  0.5686275  0.59607846 ... 0.2509804  0.19215687\n",
      "    0.19607843]\n",
      "   [0.6        0.6039216  0.6039216  ... 0.3137255  0.22745098\n",
      "    0.16470589]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6666667  0.6666667  0.67058825 ... 0.99607843 0.99607843\n",
      "    0.99607843]\n",
      "   [0.67058825 0.68235296 0.6901961  ... 0.99607843 0.99607843\n",
      "    0.99215686]\n",
      "   [0.6627451  0.6784314  0.68235296 ... 1.         0.99607843\n",
      "    0.9843137 ]\n",
      "   ...\n",
      "   [0.25490198 0.27058825 0.25490198 ... 0.18431373 0.16078432\n",
      "    0.16862746]\n",
      "   [0.2784314  0.27058825 0.29803923 ... 0.16078432 0.14509805\n",
      "    0.15686275]\n",
      "   [0.27450982 0.29803923 0.32156864 ... 0.16862746 0.13725491\n",
      "    0.13333334]]\n",
      "\n",
      "  [[0.40392157 0.3529412  0.38431373 ... 0.9137255  0.88235295\n",
      "    0.8117647 ]\n",
      "   [0.42352942 0.3647059  0.38039216 ... 0.8862745  0.91764706\n",
      "    0.7647059 ]\n",
      "   [0.41568628 0.43529412 0.37254903 ... 0.9490196  0.84313726\n",
      "    0.7176471 ]\n",
      "   ...\n",
      "   [0.45882353 0.4509804  0.44313726 ... 0.21176471 0.19607843\n",
      "    0.15686275]\n",
      "   [0.5568628  0.49019608 0.53333336 ... 0.19607843 0.16470589\n",
      "    0.14117648]\n",
      "   [0.5254902  0.61960787 0.57254905 ... 0.20392157 0.1764706\n",
      "    0.14901961]]\n",
      "\n",
      "  [[0.28235295 0.33333334 0.2627451  ... 0.76862746 0.72156864\n",
      "    0.73333335]\n",
      "   [0.31764707 0.4        0.30588236 ... 0.7764706  0.7490196\n",
      "    0.7372549 ]\n",
      "   [0.34901962 0.35686275 0.36078432 ... 0.7411765  0.7372549\n",
      "    0.72156864]\n",
      "   ...\n",
      "   [0.5137255  0.49411765 0.4862745  ... 0.14901961 0.11764706\n",
      "    0.13333334]\n",
      "   [0.42352942 0.48235294 0.5254902  ... 0.12941177 0.11764706\n",
      "    0.16470589]\n",
      "   [0.42352942 0.44705883 0.5058824  ... 0.17254902 0.12941177\n",
      "    0.14901961]]]]\n",
      "lableeeee [3 2 1 2 2 3 1 2 2 1 0 2 2 1 3 1 1 1 3 1 3 1 3 2 2 1 1 0 2 1 1 2 1 3 2 2 2\n",
      " 2 3 2 3 2 2 3 2 2 1 3 1 1 1 2 0 1 2 1 2 1 1 2 1 2 2 1 2 2 1 1 2 2 2 1 3 1\n",
      " 2 1 1 1 3 2 2 3 1 3 1 2 2 2 2 0 3 2 3 3 3 2 2 3 3 1 2 1 2 3 1 2 1 2 1 3 1\n",
      " 2 2 2 2 2 1 2 1 1 2 2 2 3 3 2 1 2 0 1 1 3 2 1 0 1 3 2 1 1 3 1 2 0 2 1 3 2\n",
      " 3 2 3 2 3 3 0 3 2 1 3 2 3 2 2 2 1 2 1 0 2 2 1 3 3 3 2 1 2 1 1 2 1 3 1 2 1\n",
      " 1 2 1 3 2 1 1 3 2 3 1 1 2 1 2 3 3 1 3 1 1 3 1 2 1 1 1 2 1 0 2 1 2 1 3 2 2\n",
      " 3 2 2 1 2 1 2 1 3 1 0 1 3 1 3 2 1 1 3 2 3 1 1 1 3 2 3 2 2 2 2 2 2 2 3 0 2\n",
      " 3 1 3 1 2 1 2 2 2 3 1 2 3 1 0 1 2 3 3 2 1 2 3 1 1 3 3 2 1 3 3 1 1 1 3 2 3\n",
      " 1 1 3 1 2 0 1 1 2 1 3 1 2 3 0 3 1 2 2 2 2 1 3 0 2 2 2 2 1 3 2 2 3 3 1 1 2\n",
      " 1 1 2 2 0 1 2 2 2 3 1 2 3 2 3 2 1 3 2 2 1 1 3 1 1 1 1 3 1 2 1 2 3 3 2 1 1\n",
      " 2 1 1 2 2 3 1 1 0 1 1 2 2 0 1 2 3 1 1 3 1 3 0 3 3 1 2 2 3 2 2 1 2 1 1 2 2\n",
      " 0 1 3 1 2 2 1 1 2 0 2 1 2 3 2 1 0 2 3 1 2 0 2 2 2 1 0 1 1 1 1 2 3 3 1 2 3\n",
      " 3 3 3 1 1 1 3 1 1 2 2 3 1 3 2 2 1 1 1 2 1 3 3 2 2 1 1 2 3 3 3 2 2 2 1 2 2\n",
      " 0 3 1 1 1 2 1 0 1 1 1 3 1 1 2 0 1 1 1 3 2 2 3 3 2 1 3 3 1 0 1 1 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 1 2 3 1 2 1 3 2 1 1 1 1 1 1 3 2 2 1 2 3 2 1 1 2 1 2 2 2 1\n",
      " 1 0 2 2 3 2 2 1 2 2 1 3 1 1 3 1 3 0 3 2 2 1 2 2 2 2 3 3 3 3 2 3 3 3 3 3 1\n",
      " 1 2 3 2 1 2 2 2 1 3 3 1 3 2 1 1 3 2 2 3 1 2 1 3 1 1 1 3 3 2 3 2 1 2 2 2 1\n",
      " 1 1 1 0 2 0 2 2 1 1 0 3 3 3 3 2 3 1 0 2 2 0 1 1 0 2 1 3 1 1 1 1 3 2 1 2 1\n",
      " 3 1 1 2 1 2 3 1 1 3 1 2 3 2 3 1 1 1 3 2 2 2 1 1 2 1 3 1 1 1 3 1 3 3 2]\n",
      "shapeee (701,)\n"
     ]
    }
   ],
   "source": [
    "print(cooked_img_list_train.shape)\n",
    "print(len(cooked_img_list_train))\n",
    "print(type(cooked_img_list_train))\n",
    "print(cooked_img_list_train)\n",
    "print('lableeeee',cooked_lable_list_train)\n",
    "print('shapeee', cooked_lable_list_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapeee (701, 1)\n"
     ]
    }
   ],
   "source": [
    "cooked_lable_list_train =  np.expand_dims(cooked_lable_list_train, axis=1)\n",
    "print('shapeee', cooked_lable_list_train.shape)\n",
    "#cooked_lable_list_train =  np.expand_dims(cooked_lable_list_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapeee (701, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "cooked_lable_list_train =  np.expand_dims(cooked_lable_list_train, axis=1)\n",
    "print('shapeee', cooked_lable_list_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_12 to have shape (None, 149, 1) but got array with shape (1, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-3449e9c055e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcooked_img_list_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcooked_lable_list_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m    802\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m           exception_prefix='target')\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    193\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_12 to have shape (None, 149, 1) but got array with shape (1, 1, 1)"
     ]
    }
   ],
   "source": [
    "model.fit(cooked_img_list_train, cooked_lable_list_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
